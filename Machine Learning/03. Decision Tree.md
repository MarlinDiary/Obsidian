## 1. 监督学习复习
- **定义**：监督学习使用带标签的数据进行训练，数据包括：
  - **特征（Features）**：描述样本的属性，例如牛奶摄入量。
  - **标签（Labels）**：预测目标，例如“是否生病”（1 表示生病，0 表示不生病）。
- **目标**：通过历史数据训练模型，用于预测新数据的标签。
- **基线方法**：
  - 最简单的方法是选择数据中最常见的标签（众数）。
  - 示例：若 80% 样本标签为 1，则预测所有新样本为 1，准确率为 80%。
  - 模型应优于此基线。

---

## 2. 决策树简介
- **定义**：决策树是一种监督学习模型，通过一系列 if-else 规则预测标签。
- **结构**：
  - **根节点（Root Node）**：树的起点，包含第一个决策规则。
  - **内部节点（Internal Nodes）**：中间决策点，包含后续规则。
  - **叶节点（Leaf Nodes）**：树的终点，输出预测结果。
- **学习过程**：在假设空间（hypothesis space）中搜索，找到最佳模型。
- **可视化**：规则将特征空间分割成不同区域，最终指向预测标签。

---

## 3. 决策树桩（Decision Stumps）
- **定义**：最简单的决策树，仅包含一个决策规则和两个叶节点。
- **示例**：
  - 规则：若牛奶摄入量 > 0.5，则预测生病（1），否则不生病（0）。
- **评估**：使用**分类准确率（Classification Accuracy）**，即正确预测的样本比例。

---

## 4. 决策树的学习过程
- **贪婪递归分裂（Greedy Recursive Splitting）**：
  1. 从根节点开始，选择最佳规则（例如牛奶 > 0.5）。
  2. 根据规则将数据集分为两个子集。
  3. 对每个子集重复分裂，直到满足停止条件。
- **停止条件**：
  - 叶节点中样本属于同一类别（纯净）。
  - 达到预设最大深度。
  - 信息增益低于某个阈值。

---

## 5. 信息增益（Information Gain）
- **问题**：分类准确率可能不足以选择最佳规则，尤其在内部节点。
- **定义**：==信息增益衡量分裂后数据的“纯度”提升==。
- **熵（Entropy）**：
  - 衡量数据随机性，公式：  
    $\text{Entropy} = -p \log_2 p - (1 - p) \log_2 (1 - p)$  
    （\( p \) 为正例比例）。
  - **熵 = 0**：数据完全纯净（全为同一类）。
  - **熵 = 1**：数据完全随机（正负例各 50%）。
- **信息增益公式**：  
  $\text{Information Gain} = \text{Entropy}_{\text{before}} - \sum (\frac{n_{\text{branch}}}{n} \times \text{Entropy}_{\text{branch}})$  
  - 表示分裂前后熵的减少量。
- **作用**：选择使分裂后熵减少最多的规则，即使当前分类准确率不变，也可能为后续分裂创造条件。

---

## 6. 决策树构建示例
- **步骤**：
  1. 从全数据集开始，计算每个特征的规则（例如牛奶 > 0.5），选择信息增益最高的。
  2. 根据规则分裂数据为两个子集。
  3. 对每个子集重复此过程（例如左子集：鸡蛋 > 1；右子集：鱼 > 0）。
  4. 继续分裂直到叶节点纯净或停止条件触发。
- **结果**：生成一棵树，逐步分割特征空间为纯净区域。

---

## 7. 决策树剪枝（Pruning）
- **问题**：树过深可能过拟合训练数据，在新数据上表现差。
- **方法**：**减错误剪枝（Reduced Error Pruning）**
  - ==从底部开始，检查每个内部节点==。
  - 若将节点替换为叶节点（取多数类）后准确率不下降，则剪枝。
- **目标**：提高泛化能力，适应未见数据。

---

## 8. 决策树的优缺点
- **优点**：
  - 易于实现和解释。
  - 预测速度快。
  - 可处理缺失值。
- **缺点**：
  - 难以找到全局最优规则集。
  - 贪婪算法可能导致次优解。
  - 可能需要深树才能达到高准确率。

---

## 9. 无监督学习简介
- **定义**：数据无标签，目标是发现模式或结构。
- **任务**：
  - 异常检测（Outlier Detection）
  - 聚类（Clustering）
  - 关联规则（Association Rules）
  - 数据可视化（Data Visualization）
- **示例**：客户细分、推荐系统。

---

## 10. 总结
- **监督学习**：用带标签数据训练模型，决策树是典型方法。
- **决策树构建**：通过贪婪递归分裂，使用信息增益选择规则。
- **剪枝**：用减错误剪枝防止过拟合。
- **无监督学习**：探索无标签数据的内在结构。

---

**课后阅读建议**：查阅机器学习书籍中的决策树章节，加深理解。