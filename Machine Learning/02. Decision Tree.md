## 课程回顾

- **机器学习（Machine Learning）** 是人工智能（AI）的一个子领域，算法通过数据学习模式，而无需手动编写规则。
- **监督学习（Supervised Learning）** 是机器学习的一种类型，数据集包含输入特征和目标标签（label），算法通过这些数据学习预测规则。
- **模型（Model）** 是算法从数据中学习的规则，可以用于未来的数据预测或分类。

---

## 决策树（Decision Trees）

### **引入案例**

- 记录每日饮食数据（鸡蛋、牛奶、鱼类等），并标记自己是否生病（0=未生病，1=生病）。
- 目标：找出饮食与生病之间的模式，并用于未来预测。
- 挑战：
    - 可能对多个食物过敏，而不仅仅是一个。
    - 量的多少可能影响结果（如少量无影响，但超过阈值后生病）。
    - 食物间可能有交互作用，单独观察某种食物可能得不到正确结论。

---

### **决策树的核心概念**

#### **基本术语**

- **示例（Example）**：数据表中的一行，每天的食物摄入和生病状态。
- **特征（Feature）**：数据表中的列（鸡蛋、牛奶等）。
- **标签（Class Label）**：需要预测的值（生病/未生病）。
- **分类器（Classifier）**：监督学习模型的输出，能够对新数据进行分类。

---

## **决策树的结构**

- **决策树是一系列嵌套的 if-else 规则**：
    - 例如：
        
        ```plaintext
        如果 牛奶 > 0.5 升 → 预测 生病
        否则：
          如果 鸡蛋 > 1 个 → 预测 生病
          否则 → 预测 未生病
        ```
        
    - 另一种可视化方式：树形结构
        
        ```plaintext
               [牛奶 > 0.5？]
                /       \
           是（生病）  否 → [鸡蛋 > 1？]
                           /      \
                      是（生病）   否（未生病）
        ```
        
- **决策树学习 = 在假设空间中搜索最优模型**：
    - 搜索最优的规则组合，使得对新数据的预测最准确。
    - 不能穷举所有可能的规则，因此需要有效的搜索方法。

---

## **决策树的生成过程**

### **1. 决策桩（Decision Stump）**

- **定义**：只有一个决策节点的简单决策树，只有一个分裂（split）。
- **目标**：找到最优的分裂点，使得分类正确率最高。

### **2. 选择最佳分裂规则**

- **分类准确率（Classification Accuracy）**：
    - 计算每个特征的不同阈值，选择使分类正确率最高的分裂点。
- **示例计算**（假设 `蛋 > 1` 作为规则）：
    - `蛋 > 1` 正确预测 5/6 次，分类准确率为 **5/6 = 83.3%**。
    - 选择分类正确率最高的规则作为决策桩的分裂点。

---

## **决策树的递归生成（Recursive Splitting）**

- **贪心策略（Greedy Recursive Splitting）**：
    - **第一步**：找到最佳的决策桩（最优的单个特征分裂点）。
    - **第二步**：在分裂后的子集上重复这个过程，构建更深的树。
    - **终止条件**：
        - 不能再提高分类正确率时停止。
        - 叶节点（最终分类结果）不再需要继续分裂。

---

## **监督学习的通用表示**

在数学上，我们可以使用 **矩阵表示法** 来描述数据：

- **特征矩阵** `X`：
    - `X[i,j]` 代表第 `i` 个示例的第 `j` 个特征值。
    - `X[i]` 代表第 `i` 行的所有特征值（即一个样本的全部输入）。
- **标签 `Y`**：
    - `Y[i]` 代表第 `i` 个示例的真实标签（生病/未生病）。
    - `Y^` 代表模型预测的标签。

---

## **训练 vs 预测**

- **训练阶段（Training Phase）**：
    - 目标：使用 `X` 和 `Y` 找到最优决策树模型。
- **预测阶段（Prediction Phase）**：
    - 输入新的 `X`（仅特征，无标签），模型输出 `Y^`（预测值）。
    - `Y^ != Y` 时，计算误差，衡量模型效果。

---

## **关键概念总结**

- 监督学习依赖**带标签数据**，用于训练模型进行预测。
- **决策树**是一种基于**特征分裂**的分类模型。
- **贪心递归分裂** 是生成决策树的常见方法，每次选择最优分裂点，逐步构建树。
- **决策桩**是最简单的决策树，仅包含一个分裂。
- **分类准确率**是衡量分裂质量的指标之一，影响分裂选择。
- 未来课程将介绍**决策树剪枝（Pruning）** 和 **集成学习（Ensemble Learning）** 技术，以提升决策树的性能。

---

## **下节课预告**

- **深入决策树构造**：
    - 继续探索**如何选择最佳分裂点**。
    - **避免过拟合**：什么时候应该剪枝？
- **扩展应用**：
    - 如何结合多个决策树（如随机森林）提高预测能力？